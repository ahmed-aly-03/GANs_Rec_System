{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WR2sGn-JFlIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c7daa2-819e-4176-9e5b-cb2a4ab5181b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMgmChsHSu1R"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class GAN_Rec(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, number_of_items):\n",
        "      super().__init__()\n",
        "\n",
        "      self.generator = nn.Sequential(\n",
        "            nn.Linear(number_of_items, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, number_of_items),\n",
        "            nn.Sigmoid()\n",
        "          )\n",
        "\n",
        "\n",
        "      self.discriminator = nn.Sequential(\n",
        "            nn.Linear(number_of_items, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def generate(self, user_data, mask = True):\n",
        "      generated_recs = self.generator(user_data)\n",
        "\n",
        "      if mask == False:\n",
        "        return generated_recs * 5\n",
        "\n",
        "      masked_recs = torch.mul(generated_recs, user_data)\n",
        "      return masked_recs\n",
        "\n",
        "    def discriminate(self, masked_recs):\n",
        "      return self.discriminator(masked_recs)\n",
        "\n",
        "    def d_loss(self, u_data):\n",
        "      u_data = u_data[0]\n",
        "      dis_real = self.discriminate(u_data)\n",
        "      dis_fake = self.discriminate(self.generate(u_data))\n",
        "      return -torch.mean(torch.log(1. - dis_fake) + torch.log(dis_real))\n",
        "\n",
        "    def g_loss(self, user_Data):\n",
        "      user_Data = user_Data[0]\n",
        "      masked_recs = self.generate(user_Data)\n",
        "      dis_output = self.discriminate(masked_recs)\n",
        "      return -torch.mean(torch.log(dis_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJcEzk2ekhL8"
      },
      "outputs": [],
      "source": [
        "def train_GANs_REC(model, dataloader, epochs, learning_rate, device = 'cuda'):\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  optimizer_g = torch.optim.Adam(model.generator.parameters(), lr=learning_rate)\n",
        "  optimizer_d = torch.optim.Adam(model.discriminator.parameters(), lr=learning_rate)\n",
        "  for epoch in range(epochs):\n",
        "    for user_data in dataloader:\n",
        "\n",
        "      user_data = user_data.to(device)\n",
        "\n",
        "      optimizer_d.zero_grad()\n",
        "      d_loss = model.d_loss([user_data])\n",
        "      d_loss.backward()\n",
        "      optimizer_d.step()\n",
        "\n",
        "\n",
        "      optimizer_g.zero_grad()\n",
        "      g_loss = model.g_loss([user_data])\n",
        "      g_loss.backward()\n",
        "      optimizer_g.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poME_1ocGx54"
      },
      "outputs": [],
      "source": [
        "def test_GAN(model, dataloader, device = 'cuda'):\n",
        "  model.to(device)\n",
        "  predicted_recs = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for user_data in dataloader:\n",
        "      user_data = user_data.to(device)\n",
        "      recs = model.generate(user_data, False)\n",
        "      recs = recs.squeeze().tolist()\n",
        "      predicted_recs.append(recs)\n",
        "  return predicted_recs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8nLZA5-Rehz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data = pd.read_csv( '/content/drive/MyDrive/LLM Recommender Research project/Coding Resources/Baseline Models/MovieLen1M/ratings.dat',\n",
        "                   sep = '::', header = None, engine = 'python',\n",
        "                   names = ['UserIDs', 'MovieIDs', 'Ratings'],\n",
        "                    usecols = [0,1,2])\n",
        "\n",
        "\n",
        "data = data.pivot_table(index = \"UserIDs\", columns = \"MovieIDs\", values = \"Ratings\")\n",
        "\n",
        "data = data.fillna(0)\n",
        "data = data.to_numpy()\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size = 0.2)\n",
        "\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 16, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 1, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdx8GwmJlVig",
        "outputId": "1c1ff42b-8ba3-4c94-92c1-0a1439f541af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], D Loss: 1.3854, G Loss: 0.7234\n",
            "Epoch [2/100], D Loss: 1.3896, G Loss: 0.7638\n",
            "Epoch [3/100], D Loss: 1.4121, G Loss: 0.6727\n",
            "Epoch [4/100], D Loss: 1.4157, G Loss: 0.6649\n",
            "Epoch [5/100], D Loss: 1.4308, G Loss: 0.6980\n",
            "Epoch [6/100], D Loss: 1.3718, G Loss: 0.6867\n",
            "Epoch [7/100], D Loss: 1.3825, G Loss: 0.7053\n",
            "Epoch [8/100], D Loss: 1.3754, G Loss: 0.7169\n",
            "Epoch [9/100], D Loss: 1.4172, G Loss: 0.7023\n",
            "Epoch [10/100], D Loss: 1.4284, G Loss: 0.7377\n",
            "Epoch [11/100], D Loss: 1.4154, G Loss: 0.7240\n",
            "Epoch [12/100], D Loss: 1.3668, G Loss: 0.6722\n",
            "Epoch [13/100], D Loss: 1.4154, G Loss: 0.6785\n",
            "Epoch [14/100], D Loss: 1.3568, G Loss: 0.6970\n",
            "Epoch [15/100], D Loss: 1.3603, G Loss: 0.7058\n",
            "Epoch [16/100], D Loss: 1.3939, G Loss: 0.6913\n",
            "Epoch [17/100], D Loss: 1.3872, G Loss: 0.7100\n",
            "Epoch [18/100], D Loss: 1.3630, G Loss: 0.7155\n",
            "Epoch [19/100], D Loss: 1.3637, G Loss: 0.7140\n",
            "Epoch [20/100], D Loss: 1.4036, G Loss: 0.6812\n",
            "Epoch [21/100], D Loss: 1.3854, G Loss: 0.6907\n",
            "Epoch [22/100], D Loss: 1.4065, G Loss: 0.6929\n",
            "Epoch [23/100], D Loss: 1.4046, G Loss: 0.7144\n",
            "Epoch [24/100], D Loss: 1.3848, G Loss: 0.6967\n",
            "Epoch [25/100], D Loss: 1.3632, G Loss: 0.7025\n",
            "Epoch [26/100], D Loss: 1.3989, G Loss: 0.6632\n",
            "Epoch [27/100], D Loss: 1.3867, G Loss: 0.6880\n",
            "Epoch [28/100], D Loss: 1.3770, G Loss: 0.7025\n",
            "Epoch [29/100], D Loss: 1.4007, G Loss: 0.6958\n",
            "Epoch [30/100], D Loss: 1.3874, G Loss: 0.6944\n",
            "Epoch [31/100], D Loss: 1.3842, G Loss: 0.7035\n",
            "Epoch [32/100], D Loss: 1.3935, G Loss: 0.6929\n",
            "Epoch [33/100], D Loss: 1.3866, G Loss: 0.6890\n",
            "Epoch [34/100], D Loss: 1.3794, G Loss: 0.6888\n",
            "Epoch [35/100], D Loss: 1.4022, G Loss: 0.7041\n",
            "Epoch [36/100], D Loss: 1.3849, G Loss: 0.6950\n",
            "Epoch [37/100], D Loss: 1.3935, G Loss: 0.6986\n",
            "Epoch [38/100], D Loss: 1.3870, G Loss: 0.6824\n",
            "Epoch [39/100], D Loss: 1.3822, G Loss: 0.6957\n",
            "Epoch [40/100], D Loss: 1.3888, G Loss: 0.6991\n",
            "Epoch [41/100], D Loss: 1.3868, G Loss: 0.6947\n",
            "Epoch [42/100], D Loss: 1.3776, G Loss: 0.6950\n",
            "Epoch [43/100], D Loss: 1.4026, G Loss: 0.6954\n",
            "Epoch [44/100], D Loss: 1.3877, G Loss: 0.6898\n",
            "Epoch [45/100], D Loss: 1.3855, G Loss: 0.6990\n",
            "Epoch [46/100], D Loss: 1.3983, G Loss: 0.7003\n",
            "Epoch [47/100], D Loss: 1.3928, G Loss: 0.6987\n",
            "Epoch [48/100], D Loss: 1.3908, G Loss: 0.6925\n",
            "Epoch [49/100], D Loss: 1.3948, G Loss: 0.6885\n",
            "Epoch [50/100], D Loss: 1.3875, G Loss: 0.6963\n",
            "Epoch [51/100], D Loss: 1.3865, G Loss: 0.6944\n",
            "Epoch [52/100], D Loss: 1.3932, G Loss: 0.6979\n",
            "Epoch [53/100], D Loss: 1.3902, G Loss: 0.6861\n",
            "Epoch [54/100], D Loss: 1.3931, G Loss: 0.6904\n",
            "Epoch [55/100], D Loss: 1.3885, G Loss: 0.6860\n",
            "Epoch [56/100], D Loss: 1.4012, G Loss: 0.6928\n",
            "Epoch [57/100], D Loss: 1.3993, G Loss: 0.6930\n",
            "Epoch [58/100], D Loss: 1.3898, G Loss: 0.6912\n",
            "Epoch [59/100], D Loss: 1.3835, G Loss: 0.6925\n",
            "Epoch [60/100], D Loss: 1.3842, G Loss: 0.6951\n",
            "Epoch [61/100], D Loss: 1.3840, G Loss: 0.6936\n",
            "Epoch [62/100], D Loss: 1.3850, G Loss: 0.6929\n",
            "Epoch [63/100], D Loss: 1.3854, G Loss: 0.6916\n",
            "Epoch [64/100], D Loss: 1.3875, G Loss: 0.6922\n",
            "Epoch [65/100], D Loss: 1.3886, G Loss: 0.6896\n",
            "Epoch [66/100], D Loss: 1.3832, G Loss: 0.7015\n",
            "Epoch [67/100], D Loss: 1.3838, G Loss: 0.6900\n",
            "Epoch [68/100], D Loss: 1.3847, G Loss: 0.6945\n",
            "Epoch [69/100], D Loss: 1.3908, G Loss: 0.6919\n",
            "Epoch [70/100], D Loss: 1.3969, G Loss: 0.6907\n",
            "Epoch [71/100], D Loss: 1.3891, G Loss: 0.6930\n",
            "Epoch [72/100], D Loss: 1.3887, G Loss: 0.6881\n",
            "Epoch [73/100], D Loss: 1.3815, G Loss: 0.6951\n",
            "Epoch [74/100], D Loss: 1.3867, G Loss: 0.6967\n",
            "Epoch [75/100], D Loss: 1.3939, G Loss: 0.6938\n",
            "Epoch [76/100], D Loss: 1.3844, G Loss: 0.6924\n",
            "Epoch [77/100], D Loss: 1.3878, G Loss: 0.6967\n",
            "Epoch [78/100], D Loss: 1.3859, G Loss: 0.6991\n",
            "Epoch [79/100], D Loss: 1.3871, G Loss: 0.6895\n",
            "Epoch [80/100], D Loss: 1.3937, G Loss: 0.6921\n",
            "Epoch [81/100], D Loss: 1.3828, G Loss: 0.6931\n",
            "Epoch [82/100], D Loss: 1.3926, G Loss: 0.6891\n",
            "Epoch [83/100], D Loss: 1.3829, G Loss: 0.6892\n",
            "Epoch [84/100], D Loss: 1.3801, G Loss: 0.6869\n",
            "Epoch [85/100], D Loss: 1.3896, G Loss: 0.6955\n",
            "Epoch [86/100], D Loss: 1.3804, G Loss: 0.6934\n",
            "Epoch [87/100], D Loss: 1.3884, G Loss: 0.6930\n",
            "Epoch [88/100], D Loss: 1.3903, G Loss: 0.6973\n",
            "Epoch [89/100], D Loss: 1.3859, G Loss: 0.6943\n",
            "Epoch [90/100], D Loss: 1.3896, G Loss: 0.6912\n",
            "Epoch [91/100], D Loss: 1.3891, G Loss: 0.6924\n",
            "Epoch [92/100], D Loss: 1.3900, G Loss: 0.6960\n",
            "Epoch [93/100], D Loss: 1.3905, G Loss: 0.6897\n",
            "Epoch [94/100], D Loss: 1.3846, G Loss: 0.6942\n",
            "Epoch [95/100], D Loss: 1.3851, G Loss: 0.6946\n",
            "Epoch [96/100], D Loss: 1.3877, G Loss: 0.6915\n",
            "Epoch [97/100], D Loss: 1.3840, G Loss: 0.6911\n",
            "Epoch [98/100], D Loss: 1.3860, G Loss: 0.6961\n",
            "Epoch [99/100], D Loss: 1.3946, G Loss: 0.6987\n",
            "Epoch [100/100], D Loss: 1.3909, G Loss: 0.6926\n"
          ]
        }
      ],
      "source": [
        "model = GAN_Rec(len(data[0]))\n",
        "train_GANs_REC(model, train_loader, 100, 1e-4)\n",
        "predicted_recs = test_GAN(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def get_predictions(rating_matrix, recon_rating_matrix):\n",
        "  predictions = []\n",
        "  for i in range(len(rating_matrix)):\n",
        "    for j in range(len(rating_matrix[0])):\n",
        "      t = (i, rating_matrix[i][j], recon_rating_matrix[i][j])\n",
        "      predictions.append(t)\n",
        "  return predictions\n",
        "\n",
        "def precision_recall_at_k(predictions, k=100, threshold=3.0):\n",
        "\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, true_r, est in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(\n",
        "            ((true_r >= threshold) and (est >= threshold))\n",
        "            for (est, true_r) in user_ratings[:k]\n",
        "        )\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "        precision = sum(rating for rating in precisions.values()) / len(precisions)\n",
        "        recall = sum(rating for rating in recalls.values()) / len(recalls)\n",
        "    return precision, recall\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    return 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "3NeBMQZCkU3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions(test_data.numpy(), predicted_recs)\n",
        "precision, recall = precision_recall_at_k(predictions)\n",
        "f1 = f1_score(precision, recall)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zUS4qaFqkyf",
        "outputId": "8f41ab58-ebfe-4a13-c983-d169042be0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.035033112582781495\n",
            "Recall: 0.02583352879313141\n",
            "F1 Score: 0.029738093055959293\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}